{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Aug  8 01:49:00 2019\n",
    "\n",
    "@author: Yuguang Wang & Yanan Wang\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Processing data for data_file/test_data_surv.xlsx ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/song-lab/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:123: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/home/song-lab/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:124: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "def create_samples(file_name):\n",
    "    subdir = '_{}/'.format(file_name.split(\".\")[0])\n",
    "    # critical distance 20 \\mu m, pix width 0.5 \\mu m\n",
    "    critical = 20/0.5\n",
    "    num_node = 100\n",
    "    adj = list()\n",
    "    feature = list()\n",
    "    label = list()\n",
    "    pid = list()\n",
    "    pid_name = list()\n",
    "    coor = list()\n",
    "    edge_index = list()\n",
    "    edge_coor = list()\n",
    "    edge_attr = list()\n",
    "    factor_flag = 'selected_new'\n",
    "    #factor_flag = 'selected'\n",
    "    #factor_flag = 'full'\n",
    "    sv_dir = \"data/\" + factor_flag + subdir\n",
    "    if not os.path.exists(sv_dir):\n",
    "        os.makedirs(sv_dir)\n",
    "    \n",
    "    print('****** Processing data for %s ******' % file_name)\n",
    "    df_diagnosis = pd.read_excel(file_name)\n",
    "    id_participant = df_diagnosis['Id']\n",
    "    num_id_1 = len(id_participant)\n",
    "    survival_time_all = df_diagnosis['survival_time'].array\n",
    "    \n",
    "    for kid, row in df_diagnosis.iterrows():\n",
    "        ld_csv = row['file_path']\n",
    "        old_new_flag = ld_csv.split(\"/\")[2]\n",
    "        #print(ld_csv)\n",
    "        #print(old_new_flag)\n",
    "        \n",
    "        label1 = row['prognosis_label']\n",
    "        df_csv = pd.read_csv(ld_csv)\n",
    "        # extract the features\n",
    "        if factor_flag == 'full': # from \"DAPI (DAPI) Nucleus Intensity\" to end\n",
    "            lv = np.linspace(22,59,38,dtype=int)\n",
    "        if factor_flag == 'selected_old':\n",
    "            lv = np.array([11,12,18,35,36,37,38,39],dtype=np.int)\n",
    "        if(old_new_flag == 'stomach_csv_1' and factor_flag == 'selected_new'):\n",
    "            lv = np.concatenate((np.linspace(20,44,25,dtype=int),np.linspace(50,59,10,dtype=int)))\n",
    "        elif(old_new_flag == 'stomach_csv_2' and factor_flag == 'selected_new'):\n",
    "            lv = np.concatenate((np.linspace(32,56,25,dtype=int),np.linspace(62,71,10,dtype=int)))\n",
    "        feature_all = df_csv.take(lv,axis=1).values\n",
    "        #print(feature_all)\n",
    "        feature_all = feature_all/(feature_all.max(axis=0)+0.00000000000001) # Add normalization\n",
    "        #print(feature_all)\n",
    "        \n",
    "        \n",
    "        # compute adjacency matrix\n",
    "        xmin = np.array(df_csv['XMin'])\n",
    "        xmax = np.array(df_csv['XMax'])\n",
    "        ymin = np.array(df_csv['YMin'])\n",
    "        ymax = np.array(df_csv['YMax'])\n",
    "        num_cell = len(xmin)\n",
    "        if np.mod(num_cell,num_node)==0:\n",
    "            num_graph = int(num_cell/num_node)\n",
    "        else:\n",
    "            num_graph = int(num_cell/num_node)+1\n",
    "        # compute the centre coordinates of cells\n",
    "        xc = (xmin+xmax)/2\n",
    "        yc = (ymin+ymax)/2\n",
    "        #% compute the adjacency matrix for each graph\n",
    "        # deal with the graphs except the last\n",
    "        for i in range(num_graph-1):\n",
    "            A = np.zeros([num_node,num_node])\n",
    "            coor1 = list()\n",
    "            coor1.append(xc[i*num_node:(i+1)*num_node])\n",
    "            coor1.append(yc[i*num_node:(i+1)*num_node])\n",
    "            coor1 = np.reshape(np.array(coor1),[num_node,2])\n",
    "            edge_coor_1 = list()\n",
    "            edge_index_1 =list()\n",
    "            edge_attr_1 = list()\n",
    "            for k in range(num_node):\n",
    "                for j in range(k+1,num_node):\n",
    "                    # turn to global coordinates\n",
    "                    k1 = i*num_node + k\n",
    "                    j1 = i*num_node + j\n",
    "                    dist = np.sqrt((xc[k1]-xc[j1])**2+(yc[k1]-yc[j1])**2)\n",
    "                    if dist<critical:\n",
    "                        A[k,j] = critical/dist\n",
    "                        A[j,k] = critical/dist\n",
    "                        edge_coor_temp = np.array([xc[k1],yc[k1],xc[j1],yc[j1]],dtype=np.float64)\n",
    "                        edge_coor_1.append(edge_coor_temp)\n",
    "                        edge_coor_temp = np.array([xc[j1],yc[j1],xc[k1],yc[k1]],dtype=np.float64)\n",
    "                        edge_coor_1.append(edge_coor_temp)\n",
    "                        edge_index_temp = np.array([k,j],dtype=np.int)\n",
    "                        edge_index_1.append(edge_index_temp)\n",
    "                        edge_index_temp = np.array([j,k],dtype=np.int)\n",
    "                        edge_index_1.append(edge_index_temp)\n",
    "                        edge_attr_temp = np.array([A[k,j],A[j,k]],dtype=np.float)\n",
    "                        edge_attr_1.append(edge_attr_temp)\n",
    "            A = csr_matrix(A)\n",
    "            adj.append(A)\n",
    "            #print('kid, id_participant[kid]:',kid, id_participant[kid])\n",
    "            tissue_id = row['组织编码']\n",
    "            #print(tissue_id)\n",
    "            pid_name.append(tissue_id)\n",
    "            pid.append(kid)\n",
    "            label.append(label1)\n",
    "            coor.append(coor1)\n",
    "            edge_coor.append(np.reshape(np.array(edge_coor_1),[len(edge_coor_1),4]))\n",
    "            edge_index.append(np.reshape(np.array(edge_index_1),[len(edge_index_1),2]))\n",
    "            edge_attr.append(np.reshape(np.array(edge_attr_1),[len(edge_index_1),1]))\n",
    "            feature.append(feature_all[i*num_node:(i+1)*num_node,])\n",
    "        # deal with the last graph\n",
    "        if np.mod(num_cell,num_node)>0:\n",
    "            num_node_last = int(np.mod(num_cell,num_node))\n",
    "        else:\n",
    "            num_node_last = num_node\n",
    "        coor1 = list()\n",
    "        coor1.append(xc[(i+1)*num_node:])\n",
    "        coor1.append(yc[(i+1)*num_node:])\n",
    "        coor1 = np.reshape(np.array(coor1),[num_node_last,2])\n",
    "        A = np.zeros([num_node_last,num_node_last])\n",
    "        for k in range(num_node_last):\n",
    "            for j in range(k,num_node_last):\n",
    "                dist = np.sqrt((xc[k1]-xc[j1])**2+(yc[k1]-yc[j1])**2)\n",
    "                k1 = i*num_node + k\n",
    "                j1 = i*num_node + j\n",
    "                if dist<critical:\n",
    "                    A[k,j] = critical/dist\n",
    "                    A[j,k] = critical/dist\n",
    "                    edge_coor_temp = np.array([xc[k1],yc[k1],xc[j1],yc[j1]],dtype=np.float64)\n",
    "                    edge_coor_1.append(edge_coor_temp)\n",
    "                    edge_coor_temp = np.array([xc[j1],yc[j1],xc[k1],yc[k1]],dtype=np.float64)\n",
    "                    edge_coor_1.append(edge_coor_temp)\n",
    "                    edge_index_temp = np.array([k,j],dtype=np.int)\n",
    "                    edge_index_1.append(edge_index_temp)\n",
    "                    edge_index_temp = np.array([j,k],dtype=np.int)\n",
    "                    edge_index_1.append(edge_index_temp)\n",
    "                    edge_attr_temp = np.array([A[k,j],A[j,k]],dtype=np.float)\n",
    "                    edge_attr_1.append(edge_attr_temp)\n",
    "        A = csr_matrix(A)\n",
    "    #    print('kid, id_participant[kid]:',kid, id_participant[kid])\n",
    "        adj.append(A)\n",
    "        \n",
    "        tissue_id = row['组织编码']\n",
    "        #print(tissue_id)\n",
    "        pid.append(kid)\n",
    "        pid_name.append(tissue_id)\n",
    "        \n",
    "\n",
    "        label.append(label1)\n",
    "        coor.append(coor1)\n",
    "        edge_coor.append(np.reshape(np.array(edge_coor_1),[len(edge_coor_1),4]))\n",
    "        edge_index.append(np.reshape(np.array(edge_index_1),[len(edge_index_1),2]))\n",
    "        edge_attr.append(np.reshape(np.array(edge_attr_1),[len(edge_index_1),1]))\n",
    "        feature.append(feature_all[i*num_node:(i+1)*num_node,])\n",
    "        \n",
    "    #%% save data\n",
    "    # adj\n",
    "    sv_adj = sv_dir + 'graph' + str(len(label)) + '_node' + str(num_node) + '_weighted' + '_adj_csr' + '.mat'\n",
    "    sio.savemat(sv_adj,mdict={'adj':adj})\n",
    "    # feature\n",
    "    sv_feature = sv_dir + 'graph' + str(len(label)) + '_node' + str(num_node) + '_weighted' + '_feature' + '.mat'\n",
    "    sio.savemat(sv_feature,mdict={'feature':feature})\n",
    "    # label in survival time classes\n",
    "    sv_label = sv_dir + 'graph' + str(len(label)) + '_node' + str(num_node) + '_weighted' + '_label' + '.mat'\n",
    "    sio.savemat(sv_label,mdict={'label':label})\n",
    "    # label in participant id\n",
    "    sv_pid = sv_dir + 'graph' + str(len(label)) + '_node' + str(num_node) + '_weighted' + '_pid' + '.mat'\n",
    "    sio.savemat(sv_pid,mdict={'pid':pid})\n",
    "    # label in participant id name\n",
    "    sv_pid_name = sv_dir + 'graph' + str(len(label)) + '_node' + str(num_node) + '_weighted' + '_pid_name' + '.mat'\n",
    "    sio.savemat(sv_pid_name,mdict={'pid_name':pid_name})\n",
    "    # coordinates of nodes\n",
    "    sv_node_coor = sv_dir + 'graph' + str(len(label)) + '_node' + str(num_node) + '_weighted' + '_nodecoor' + '.mat'\n",
    "    sio.savemat(sv_node_coor,mdict={'coor':coor})\n",
    "    # index of the two ends of edges\n",
    "    sv_edge = sv_dir + 'graph' + str(len(label)) + '_node' + str(num_node) + '_weighted' + '_edge_index' + '.mat'\n",
    "    sio.savemat(sv_edge,mdict={'edge_index':edge_index})\n",
    "    # weight on each edge\n",
    "    sv_edge_attr = sv_dir + 'graph' + str(len(label)) + '_node' + str(num_node) + '_weighted' + '_edge_attr' + '.mat'\n",
    "    sio.savemat(sv_edge_attr,mdict={'edge_attr':edge_attr})\n",
    "    # coordinates of the two ends of edges\n",
    "    sv_edge_coor = sv_dir + 'graph' + str(len(label)) + '_node' + str(num_node) + '_weighted' + '_edge_coor' + '.mat'\n",
    "    sio.savemat(sv_edge_coor,mdict={'edge_coor':edge_coor})\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#create_samples(\"data_file/test_data.xlsx\")\n",
    "create_samples(\"data_file/test_data_surv.xlsx\")\n",
    "\n",
    "# for i in [0,1,2,3,4]:\n",
    "#     create_samples(\"data_file/val_data_fold_{}.xlsx\".format(i))\n",
    "#     create_samples(\"data_file/train_data_fold_{}.xlsx\".format(i))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellStar",
   "language": "python",
   "name": "cellstar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
